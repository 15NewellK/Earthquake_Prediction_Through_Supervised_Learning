{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "799b50ff",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f7f01",
   "metadata": {},
   "source": [
    "**Kristian Newell**\n",
    "\n",
    "**Course: BrainStation Data Science**\n",
    "\n",
    "**Next Notebook: 2. EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f208d4f",
   "metadata": {},
   "source": [
    "The goal of my overall project is to be able to predict earthquake depth and magnitude through supervised learning. This will allow for pre-planning to lessen the economic burden and loss of life due to earthquakes each year.\n",
    "\n",
    "The dataset used for this analysis is a public domain dataset created by the US Geological Survey and is available for download at [https://www.kaggle.com/usgs/earthquake-database]. This dataset is formatted as a CSV for easy access.\n",
    "\n",
    "The data in this dataset is comprised of a record of the date, time, location, depth, magnitude, and source of every seismic event larger than a reported magnitude of 5.5 from 1965 to 2016. I opted not to web-scrape data to fill in the recent most 5 years as time did not permit 60 years of training data should be enough. \n",
    "\n",
    "Now that my dataset has been described and we know what features and observations we can expect, it is time to read in the CSV file to begin to look at the data.\n",
    "\n",
    "The first step is going to be importing our standard tools for data loading, preprocessing, and cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4baf70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the usual toolkit required\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Loading in datetime incase I want to manipulate the date and time features\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d059c98",
   "metadata": {},
   "source": [
    "## Reading in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe275bda",
   "metadata": {},
   "source": [
    "I am now going to read in my data from the `csv` file using the pandas `read_csv` function and storing it as a DataFrame. After loading in the data I will be using `head()` method of DataFrames to view the first few lines of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab458c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting working directory\n",
    "import os\n",
    "os.chdir('C:/Users/Owner/Brainstation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a82ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in my dataset\n",
    "df=pd.read_csv('Capstone/earthquake_database.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "373ab69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Type</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Depth Error</th>\n",
       "      <th>Depth Seismic Stations</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Magnitude Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Magnitude Seismic Stations</th>\n",
       "      <th>Azimuthal Gap</th>\n",
       "      <th>Horizontal Distance</th>\n",
       "      <th>Horizontal Error</th>\n",
       "      <th>Root Mean Square</th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Location Source</th>\n",
       "      <th>Magnitude Source</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/02/1965</td>\n",
       "      <td>13:44:18</td>\n",
       "      <td>19.246</td>\n",
       "      <td>145.616</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>131.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860706</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/04/1965</td>\n",
       "      <td>11:29:49</td>\n",
       "      <td>1.863</td>\n",
       "      <td>127.352</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860737</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/05/1965</td>\n",
       "      <td>18:05:58</td>\n",
       "      <td>-20.579</td>\n",
       "      <td>-173.972</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.2</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860762</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/08/1965</td>\n",
       "      <td>18:49:43</td>\n",
       "      <td>-59.076</td>\n",
       "      <td>-23.557</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860856</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/09/1965</td>\n",
       "      <td>13:32:50</td>\n",
       "      <td>11.938</td>\n",
       "      <td>126.427</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860890</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  Latitude  Longitude        Type  Depth  Depth Error  \\\n",
       "0  01/02/1965  13:44:18    19.246    145.616  Earthquake  131.6          NaN   \n",
       "1  01/04/1965  11:29:49     1.863    127.352  Earthquake   80.0          NaN   \n",
       "2  01/05/1965  18:05:58   -20.579   -173.972  Earthquake   20.0          NaN   \n",
       "3  01/08/1965  18:49:43   -59.076    -23.557  Earthquake   15.0          NaN   \n",
       "4  01/09/1965  13:32:50    11.938    126.427  Earthquake   15.0          NaN   \n",
       "\n",
       "   Depth Seismic Stations  Magnitude Magnitude Type  ...  \\\n",
       "0                     NaN        6.0             MW  ...   \n",
       "1                     NaN        5.8             MW  ...   \n",
       "2                     NaN        6.2             MW  ...   \n",
       "3                     NaN        5.8             MW  ...   \n",
       "4                     NaN        5.8             MW  ...   \n",
       "\n",
       "   Magnitude Seismic Stations  Azimuthal Gap  Horizontal Distance  \\\n",
       "0                         NaN            NaN                  NaN   \n",
       "1                         NaN            NaN                  NaN   \n",
       "2                         NaN            NaN                  NaN   \n",
       "3                         NaN            NaN                  NaN   \n",
       "4                         NaN            NaN                  NaN   \n",
       "\n",
       "   Horizontal Error  Root Mean Square            ID  Source Location Source  \\\n",
       "0               NaN               NaN  ISCGEM860706  ISCGEM          ISCGEM   \n",
       "1               NaN               NaN  ISCGEM860737  ISCGEM          ISCGEM   \n",
       "2               NaN               NaN  ISCGEM860762  ISCGEM          ISCGEM   \n",
       "3               NaN               NaN  ISCGEM860856  ISCGEM          ISCGEM   \n",
       "4               NaN               NaN  ISCGEM860890  ISCGEM          ISCGEM   \n",
       "\n",
       "  Magnitude Source     Status  \n",
       "0           ISCGEM  Automatic  \n",
       "1           ISCGEM  Automatic  \n",
       "2           ISCGEM  Automatic  \n",
       "3           ISCGEM  Automatic  \n",
       "4           ISCGEM  Automatic  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the first few rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b573c5",
   "metadata": {},
   "source": [
    "## Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a932b9",
   "metadata": {},
   "source": [
    "Now I am going to run an `info` method to inspect the columns of my new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c194cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23412 entries, 0 to 23411\n",
      "Data columns (total 21 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Date                        23412 non-null  object \n",
      " 1   Time                        23412 non-null  object \n",
      " 2   Latitude                    23412 non-null  float64\n",
      " 3   Longitude                   23412 non-null  float64\n",
      " 4   Type                        23412 non-null  object \n",
      " 5   Depth                       23412 non-null  float64\n",
      " 6   Depth Error                 4461 non-null   float64\n",
      " 7   Depth Seismic Stations      7097 non-null   float64\n",
      " 8   Magnitude                   23412 non-null  float64\n",
      " 9   Magnitude Type              23409 non-null  object \n",
      " 10  Magnitude Error             327 non-null    float64\n",
      " 11  Magnitude Seismic Stations  2564 non-null   float64\n",
      " 12  Azimuthal Gap               7299 non-null   float64\n",
      " 13  Horizontal Distance         1604 non-null   float64\n",
      " 14  Horizontal Error            1156 non-null   float64\n",
      " 15  Root Mean Square            17352 non-null  float64\n",
      " 16  ID                          23412 non-null  object \n",
      " 17  Source                      23412 non-null  object \n",
      " 18  Location Source             23412 non-null  object \n",
      " 19  Magnitude Source            23412 non-null  object \n",
      " 20  Status                      23412 non-null  object \n",
      "dtypes: float64(12), object(9)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking the column names and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d797d58",
   "metadata": {},
   "source": [
    "Several of the columns are inconsequential to the model I would like to create, specifically: \n",
    "\n",
    "    *Depth Error \n",
    "    *Depth Seismic Stations \n",
    "    *Magnitude Type\n",
    "    *Magnitude Error\n",
    "    *Magnitude Seismic Stations\n",
    "    *Azimuthal Gap\n",
    "    *Horizontal Distance\n",
    "    *Horizontal Error\n",
    "    *Root Mean Square\n",
    "    *ID\n",
    "    *Source\n",
    "    *Location Source\n",
    "    *Magnitude Source\n",
    "    *Status\n",
    "As such I will be removing these columns from my working DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c48f9ed",
   "metadata": {},
   "source": [
    "I am choosing to remove these columns because they either contain a large amount of Nulls, like `Magnitude Error` or "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4417986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame without the unimportant rows\n",
    "earthquake_df=df[['Date','Time','Type','Latitude','Longitude','Magnitude','Depth']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c5195",
   "metadata": {},
   "source": [
    "I am inspecting the `Type` column of my DataFrame to ensure that all the rows of data I have included are for only naturally occurring seismic events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb96839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Earthquake           23232\n",
       "Nuclear Explosion      175\n",
       "Explosion                4\n",
       "Rock Burst               1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of Type\n",
    "earthquake_df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5dc0bd",
   "metadata": {},
   "source": [
    "There are still some observances in the data that were caused by seismic events other than earthquakes, so I will be dropping these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "695c8597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Pulling out and dropping all rows that are not Earthquakes\n",
    "earthquake_df.drop(earthquake_df.index.where(earthquake_df['Type']!='Earthquake').dropna(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7ba08df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "Earthquake    23232\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see only earthquakes are left\n",
    "earthquake_df.value_counts('Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb216a",
   "metadata": {},
   "source": [
    "Now that I am sure that each observation in the data represents an earthquake, the `Type` column has become irrelevant, as such I will now drop it from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "875f9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the type column as all rows are now type earthquake\n",
    "earthquake_df.drop('Type',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c419d8",
   "metadata": {},
   "source": [
    "I now want to create a single datetime feature from the two features `Date` and `Time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c6cb353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out this cell because it throws errors\n",
    "\n",
    "    # Converting date and time columns to a single datetime column\n",
    "    # pd.to_datetime(earthquake_df.Date + ' '+ earthquake_df.Time)\n",
    "\n",
    "# ParserError: Unknown string format: 1975-02-23T02:58:41.000Z 1975-02-23T02:58:41.000Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb15e119",
   "metadata": {},
   "source": [
    "There was an issue adding the two features together. The error indicates that the problematic row includes a \"T\" somewhere. Instead of combining the two columns and casting type to `datetime` in one line, I will need to do these steps piecewise to fix the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2443893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-a8ec06989b16>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  earthquake_df['DateAndTime'] = earthquake_df['Date'].str.cat(earthquake_df['Time'],sep=\" \")\n"
     ]
    }
   ],
   "source": [
    "# Combining the columns without changing type\n",
    "earthquake_df['DateAndTime'] = earthquake_df['Date'].str.cat(earthquake_df['Time'],sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bb6bb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Depth</th>\n",
       "      <th>DateAndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3378</th>\n",
       "      <td>1975-02-23T02:58:41.000Z</td>\n",
       "      <td>1975-02-23T02:58:41.000Z</td>\n",
       "      <td>8.017</td>\n",
       "      <td>124.075</td>\n",
       "      <td>5.6</td>\n",
       "      <td>623.0</td>\n",
       "      <td>1975-02-23T02:58:41.000Z 1975-02-23T02:58:41.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>1985-04-28T02:53:41.530Z</td>\n",
       "      <td>1985-04-28T02:53:41.530Z</td>\n",
       "      <td>-32.998</td>\n",
       "      <td>-71.766</td>\n",
       "      <td>5.6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1985-04-28T02:53:41.530Z 1985-04-28T02:53:41.530Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20650</th>\n",
       "      <td>2011-03-13T02:23:34.520Z</td>\n",
       "      <td>2011-03-13T02:23:34.520Z</td>\n",
       "      <td>36.344</td>\n",
       "      <td>142.344</td>\n",
       "      <td>5.8</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2011-03-13T02:23:34.520Z 2011-03-13T02:23:34.520Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date                      Time  Latitude  \\\n",
       "3378   1975-02-23T02:58:41.000Z  1975-02-23T02:58:41.000Z     8.017   \n",
       "7512   1985-04-28T02:53:41.530Z  1985-04-28T02:53:41.530Z   -32.998   \n",
       "20650  2011-03-13T02:23:34.520Z  2011-03-13T02:23:34.520Z    36.344   \n",
       "\n",
       "       Longitude  Magnitude  Depth  \\\n",
       "3378     124.075        5.6  623.0   \n",
       "7512     -71.766        5.6   33.0   \n",
       "20650    142.344        5.8   10.1   \n",
       "\n",
       "                                             DateAndTime  \n",
       "3378   1975-02-23T02:58:41.000Z 1975-02-23T02:58:41.000Z  \n",
       "7512   1985-04-28T02:53:41.530Z 1985-04-28T02:53:41.530Z  \n",
       "20650  2011-03-13T02:23:34.520Z 2011-03-13T02:23:34.520Z  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see which rows were throwing errors because they include a T\n",
    "earthquake_df[earthquake_df['DateAndTime'].str.contains('T')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a87a7",
   "metadata": {},
   "source": [
    "I have filtered out the rows that had a \"T\" present in `Date` or `Time` and it appears to be only 3 rows out of 23,232. Because these three error rows represent only 0.01% of the data, I am confident that the removal of these rows will not affect the outcome of the model. As such I will be dropping them so that I can convert the `DateAndTime` colum to data type datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e94d8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Dropping these rows\n",
    "earthquake_df.drop([3378,7512,20650], axis=0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e517185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-c36f2402b31a>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  earthquake_df['DateAndTime']=pd.to_datetime(earthquake_df['DateAndTime'])\n"
     ]
    }
   ],
   "source": [
    "# Converting DateAndTime\n",
    "earthquake_df['DateAndTime']=pd.to_datetime(earthquake_df['DateAndTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95a56016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23229 entries, 0 to 23411\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   Date         23229 non-null  object        \n",
      " 1   Time         23229 non-null  object        \n",
      " 2   Latitude     23229 non-null  float64       \n",
      " 3   Longitude    23229 non-null  float64       \n",
      " 4   Magnitude    23229 non-null  float64       \n",
      " 5   Depth        23229 non-null  float64       \n",
      " 6   DateAndTime  23229 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(4), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking to see that the column data type has been changed\n",
    "earthquake_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8c6ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the original time and date\n",
    "earthquake_df.drop(['Date','Time'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a519fd",
   "metadata": {},
   "source": [
    "The `Date` and `Time` columns have been combined into a single column `DateAndTime` of type datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1063e873",
   "metadata": {},
   "source": [
    "The data has been successfully loaded, preprocessed and cleaned; it is now ready for EDA. As such, I am going to export my cleaned DataFrame so that I may use it in my next notebook **2. EDA (Exploratory Data Analysis**. In this next workbook I will be visualizing my data as well as determining if there are any intra-feature relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b5c5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting file to CSV now that it has been cleaned\n",
    "earthquake_df.to_csv('C:/Users/Owner/Brainstation/Capstone/cleaned_df.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
